{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport shutil\nimport os\nimport csv\nfrom tabulate import tabulate\n\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, concatenate\nfrom keras.models import Model\nfrom keras.optimizers import SGD\n\n# for reproducible results\nimport tensorflow as tf\nimport random as rn\nnp.random.seed(42)\nrn.seed(12345)\nsession_conf = tf.ConfigProto(intra_op_parallelism_threads=1,\n                              inter_op_parallelism_threads=1)\nfrom keras import backend as K\ntf.set_random_seed(1234)\nsess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\nK.set_session(sess)\n# for reproducible results\n\nclass_sz = 400\nimage_sz = 64\nbatch_sz = 14\nsplit = True\nepochs_num = 30\nlr = 0.0001\nnp.random.seed(123)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "all_image_dir = '/kaggle/input/dataset/dataset'\n\ntrain_csv = 'train.csv'\nval_csv = 'val.csv'\ntest_csv = 'test.csv'\n\nclass_names = os.listdir(all_image_dir)\nclass_names.sort()\nclasses_num = len(class_names)\n\ntrain_dir_sz = int(class_sz*0.8*0.7)\nval_dir_sz = int(class_sz*0.8*0.3)\ntest_dir_sz = int(class_sz*0.2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a4c10cbf4c30dbff4aa727f09f37b0a677e41b06"
      },
      "cell_type": "code",
      "source": "def create_directory(dir_name):\n    if os.path.exists(dir_name):\n        shutil.rmtree(dir_name)\n    os.makedirs(dir_name)\n    for class_name in class_names:\n        os.makedirs(os.path.join(dir_name, class_name))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dd4d3c03ceedca1f51bec903a0c0d9bf52209867"
      },
      "cell_type": "code",
      "source": "train_dir = '/kaggle/config/dataset/train/'\nval_dir = '/kaggle/config/dataset/val/'\ntest_dir = '/kaggle/config/dataset/test/'\n\ncreate_directory(train_dir)\ncreate_directory(val_dir)\ncreate_directory(test_dir)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "664a9964334a2bd7f4f142cdb84c9d895d0b451d"
      },
      "cell_type": "code",
      "source": "indexes = np.random.permutation(class_sz)\n\ndef copy_images(start_idx, end_idx, source_dir, dest_dir, csv_file, class_num, size):\n    file = open(csv_file, 'a+')\n    writer = csv.writer(file)\n    idx = 0\n    \n    for i in range(start_idx, end_idx):\n        y = np.zeros(5)\n        y[class_num] = 1\n        src_file = os.path.join(source_dir, str(indexes[i]) + \".jpg\")\n        dst_file = os.path.join(dest_dir, str(indexes[i]) + \".jpg\")\n        writer.writerow([dst_file, y])\n        shutil.copy(src_file, dst_file)\n        idx+=1\n        \n    file.close()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6a49a65a9007fafae390dc02357e155b3f27f660"
      },
      "cell_type": "code",
      "source": "# разделение набора данных на train, valid, test\ndef split_image_dataset():\n    idx = 0\n#     очитска csv-файлов\n    open(train_csv, 'w').close()\n    open(test_csv, 'w').close()\n    open(val_csv, 'w').close()\n    \n    for class_name in class_names:\n        class_data_dir = os.path.join(all_image_dir, class_name)\n        copy_images(0, train_dir_sz,\n                    class_data_dir, os.path.join(train_dir, class_name),\n                   train_csv, idx, train_dir_sz)\n        copy_images(train_dir_sz, train_dir_sz+val_dir_sz,\n                    class_data_dir, os.path.join(val_dir, class_name),\n                   val_csv, idx, val_dir_sz)\n        copy_images(train_dir_sz+val_dir_sz, train_dir_sz+val_dir_sz+test_dir_sz,\n                class_data_dir, os.path.join(test_dir, class_name),\n                   test_csv, idx, test_dir_sz)\n        idx+=1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "72fdce3ef9e76bfd2ccf5ce42441d046fef315d3"
      },
      "cell_type": "code",
      "source": "input_img = Input(shape = (image_sz, image_sz, 3))\n\nbranch_1 = Conv2D(64, (1,1), padding='same', activation='relu')(input_img)\nbranch_1 = Conv2D(64, (3,3), padding='same', activation='relu')(branch_1)\nbranch_2 = Conv2D(64, (1,1), padding='same', activation='relu')(input_img)\nbranch_2 = Conv2D(64, (5,5), padding='same', activation='relu')(branch_2)\nbranch_3 = MaxPooling2D((3,3), strides=(1,1), padding='same')(input_img)\nbranch_3 = Conv2D(64, (1,1), padding='same', activation='relu')(branch_3)\noutput = concatenate([branch_1, branch_2, branch_3], axis = 3)\n\noutput = Flatten()(output)\nout    = Dense(classes_num, activation='softmax')(output)\n\nmodel = Model(inputs = input_img, outputs = out)\n# print (model.summary())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c818cf50077e72451b8b0c88f14e80d355510e15"
      },
      "cell_type": "code",
      "source": "if(split):\n    split_image_dataset()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e6f2e3a4f80518fd4ea995fb69a49fa34119a5d7"
      },
      "cell_type": "code",
      "source": "datagen = ImageDataGenerator(rescale=1. / 255)\n\ntrain_generator = datagen.flow_from_directory(\n    train_dir,\n    target_size=(image_sz, image_sz),\n    batch_size=batch_sz,\n    class_mode='categorical')\ntest_generator = datagen.flow_from_directory(\n    test_dir,\n    target_size=(image_sz, image_sz),\n    batch_size=1,\n    class_mode='categorical')\nval_generator = datagen.flow_from_directory(\n    val_dir,\n    target_size=(image_sz, image_sz),\n    batch_size=1,\n    class_mode='categorical')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0b39bd1aefed09265ba7c1b377baaeb47e164e49"
      },
      "cell_type": "code",
      "source": "epochs = epochs_num\nlrate = lr\ndecay = lrate/epochs\nsgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n\nmodel.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dcd6d33cc0894859707639907a8c649c102d9957"
      },
      "cell_type": "code",
      "source": "nb_train_samples = train_dir_sz*classes_num\nnb_validation_samples = val_dir_sz*classes_num\nnb_test_samples = test_dir_sz*classes_num\n\nmodel.fit_generator(\n    train_generator,\n    steps_per_epoch=nb_train_samples // batch_sz,\n    epochs=epochs,\n    validation_data=val_generator,\n    validation_steps=nb_validation_samples, \n    shuffle=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "735ebf8e26474f0474c81922b9bb44f90997dfd9",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "def per_class_accuracy():\n    results = []\n    \n    for i in range(5):\n        X = np.ndarray(shape=(test_dir_sz, image_sz, image_sz, 3),\n                             dtype=np.float32)\n        y = np.zeros((test_dir_sz,classes_num), dtype=np.int)\n        y[:,i] = np.ones(test_dir_sz)\n        \n        idx = 0\n        dirname = os.path.join(test_dir, class_names[i])\n        \n        for img in os.listdir(dirname):\n            img = load_img(os.path.join(dirname,img))\n            img = img.resize((image_sz,image_sz))\n            x = img_to_array(img)\n            x = x / 255\n            X[idx] = x\n            idx += 1\n            \n        scores = model.evaluate(np.array(X), y)\n        results.append([class_names[i],scores[1]])\n        \n    return results",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dcc3247fe382b16ea5a635547b02b1740841d20f"
      },
      "cell_type": "code",
      "source": "acc = per_class_accuracy()\nall_acc= model.evaluate_generator(test_generator, nb_test_samples)\nacc.append([\"all classes\", all_acc[1]])\n\nprint (tabulate(acc))",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}